{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled4.ipynb",
      "provenance": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyMj2bsdtL9hYcrvII6L0X7X",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samtam0714/Django-DR/blob/master/emotiondetection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhtHD-RZDlWJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization,AveragePooling2D\n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.optimizers import Adam\n",
        "from keras.regularizers import l2\n",
        "from keras.utils import np_utils\n",
        "# pd.set_option('display.max_rows', 500)\n",
        "# pd.set_option('display.max_columns', 500)\n",
        "# pd.set_option('display.width', 1000)\n",
        "\n",
        "df=pd.read_csv('fer2013.csv')\n",
        "\n",
        "# print(df.info())\n",
        "# print(df[\"Usage\"].value_counts())\n",
        "\n",
        "# print(df.head())\n",
        "X_train,train_y,X_test,test_y=[],[],[],[]\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    val=row['pixels'].split(\" \")\n",
        "    try:\n",
        "        if 'Training' in row['Usage']:\n",
        "           X_train.append(np.array(val,'float32'))\n",
        "           train_y.append(row['emotion'])\n",
        "        elif 'PublicTest' in row['Usage']:\n",
        "           X_test.append(np.array(val,'float32'))\n",
        "           test_y.append(row['emotion'])\n",
        "    except:\n",
        "        print(f\"error occured at index :{index} and row:{row}\")\n",
        "\n",
        "\n",
        "num_features = 64\n",
        "num_labels = 7\n",
        "batch_size = 64\n",
        "epochs = 100\n",
        "width, height = 48, 48\n",
        "\n",
        "\n",
        "X_train = np.array(X_train,'float32')\n",
        "train_y = np.array(train_y,'float32')\n",
        "X_test = np.array(X_test,'float32')\n",
        "test_y = np.array(test_y,'float32')\n",
        "\n",
        "train_y=np_utils.to_categorical(train_y, num_classes=num_labels)\n",
        "test_y=np_utils.to_categorical(test_y, num_classes=num_labels)\n",
        "\n",
        "#cannot produce\n",
        "#normalizing data between oand 1\n",
        "X_train -= np.mean(X_train, axis=0)\n",
        "X_train /= np.std(X_train, axis=0)\n",
        "\n",
        "X_test -= np.mean(X_test, axis=0)\n",
        "X_test /= np.std(X_test, axis=0)\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0], 48, 48, 1)\n",
        "\n",
        "X_test = X_test.reshape(X_test.shape[0], 48, 48, 1)\n",
        "\n",
        "# print(f\"shape:{X_train.shape}\")\n",
        "##designing the cnn\n",
        "#1st convolution layer\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=(X_train.shape[1:])))\n",
        "model.add(Conv2D(64,kernel_size= (3, 3), activation='relu'))\n",
        "# model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "#2nd convolution layer\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "# model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "#3rd convolution layer\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "# model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "#fully connected neural networks\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(num_labels, activation='softmax'))\n",
        "\n",
        "# model.summary()\n",
        "\n",
        "#Compliling the model\n",
        "model.compile(loss=categorical_crossentropy,\n",
        "              optimizer=Adam(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#Training the model\n",
        "model.fit(X_train, train_y,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, test_y),\n",
        "          shuffle=True)\n",
        "\n",
        "\n",
        "#Saving the  model to  use it later on\n",
        "fer_json = model.to_json()\n",
        "with open(\"fer.json\", \"w\") as json_file:\n",
        "    json_file.write(fer_json)\n",
        "model.save_weights(\"fer.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1TdMZkoPM_D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from keras.models import model_from_json\n",
        "from keras.preprocessing import image\n",
        "\n",
        "#load model\n",
        "model = model_from_json(open(\"fer.json\", \"r\").read())\n",
        "#load weights\n",
        "model.load_weights('fer.h5')\n",
        "\n",
        "\n",
        "face_haar_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
        "\n",
        "\n",
        "cap=cv2.VideoCapture(0)\n",
        "\n",
        "while True:\n",
        "    ret,test_img=cap.read()# captures frame and returns boolean value and captured image\n",
        "    if not ret:\n",
        "        continue\n",
        "    gray_img= cv2.cvtColor(test_img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    faces_detected = face_haar_cascade.detectMultiScale(gray_img, 1.32, 5)\n",
        "\n",
        "\n",
        "    for (x,y,w,h) in faces_detected:\n",
        "        cv2.rectangle(test_img,(x,y),(x+w,y+h),(255,0,0),thickness=7)\n",
        "        roi_gray=gray_img[y:y+w,x:x+h]#cropping region of interest i.e. face area from  image\n",
        "        roi_gray=cv2.resize(roi_gray,(48,48))\n",
        "        img_pixels = image.img_to_array(roi_gray)\n",
        "        img_pixels = np.expand_dims(img_pixels, axis = 0)\n",
        "        img_pixels /= 255\n",
        "\n",
        "        predictions = model.predict(img_pixels)\n",
        "\n",
        "        #find max indexed array\n",
        "        max_index = np.argmax(predictions[0])\n",
        "\n",
        "        emotions = ('angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral')\n",
        "        predicted_emotion = emotions[max_index]\n",
        "\n",
        "        cv2.putText(test_img, predicted_emotion, (int(x), int(y)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
        "\n",
        "    resized_img = cv2.resize(test_img, (1000, 700))\n",
        "    cv2.imshow('Facial emotion analysis ',resized_img)\n",
        "\n",
        "\n",
        "\n",
        "    if cv2.waitKey(10) == ord('q'):#wait until 'q' key is pressed\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}